<p align="right">English | <a href="./README_CN.md">简体中文</a></p>  


<div align="center">

  <h1>
    <span style="font-size: 1004em;">WorldArena:</span><br>
    A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models
  </h1>

  <p>
    <a href="https://worldarena.github.io/assets_common/papers/WorldArena.pdf">
      <img src="https://img.shields.io/badge/Paper-%F0%9F%93%96-darkred" alt="Paper">
    </a>
    <a href="https://worldarena.github.io/">
      <img src="https://img.shields.io/badge/Project-%F0%9F%94%97-blue" alt="Project">
    </a>
    <a href="https://huggingface.co/spaces/WorldArena/WorldArena">
      <img src="https://img.shields.io/badge/Leaderboard-%F0%9F%94%97-yellow" alt="Leaderboard">
    </a>
    <a href="https://huggingface.co/datasets/worldbench/videogen">
      <img src="https://img.shields.io/badge/Dataset-%F0%9F%94%97-green" alt="Dataset">
    </a>
  </p>

</div>



### :grey_question: Is your driving world model an all-around player? 

- This work presents `WorldLens`, a unified benchmark encompassing evaluations on $^1$**Generation**, $^2$**Reconstruction**, $^3$**Action-Following**, $^4$**Downstream Task**, and $^5$**Human Preference**, across **a total of 24 dimensions** spanning visual realism, geometric consistency, functional reliability, and perceptual alignment.
- We observe no single model dominates across all axes, highlighting the need for balanced progress toward physically and behaviorally realistic world modeling.
- For additional visual examples, kindly refer to our : [Project Page](https://worldarena.github.io/).
